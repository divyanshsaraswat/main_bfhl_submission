# Bill Extraction API

Extract structured line item data from medical bills with high accuracy.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Start server
python run.py
```

Server runs at: **http://localhost:8000**

## ğŸ“‹ API

### POST `/extract`

Extract bill data from a document URL.

**Request:**
```json
{
  "document": "https://example.com/bill.png"
}
```

**Response:**
```json
{
  "is_success": true,
  "token_usage": {
    "total_tokens": 0,
    "input_tokens": 0,
    "output_tokens": 0
  },
  "data": {
    "pagewise_line_items": [
      {
        "page_no": "1",
        "page_type": "Bill Detail",
        "bill_items": [
          {
            "item_name": "Consultation Fee",
            "item_amount": 500.0,
            "item_rate": 500.0,
            "item_quantity": 1.0
          }
        ]
      }
    ],
    "total_item_count": 1
  }
}
```

### Other Endpoints

- `GET /` - Service info
- `GET /health` - Health check
- `GET /docs` - Interactive API docs

## ğŸ§ª Testing

```bash
# Test the API
python test_hackrx_api.py

# Or use curl
curl -X POST "http://localhost:8000/extract" \
  -H "Content-Type: application/json" \
  -d '{"document": "YOUR_DOCUMENT_URL"}'
```

## âš™ï¸ Configuration

### Optional: Google Cloud Vision (Recommended)

For best OCR accuracy:

1. Get service account JSON from [Google Cloud Console](https://console.cloud.google.com/)
2. Enable Cloud Vision API
3. Set environment variable:
   ```bash
   set GOOGLE_APPLICATION_CREDENTIALS=path/to/key.json
   ```

Without it, the API uses fallback OCR (lower accuracy).

## ğŸ“ Project Structure

```
BFHL/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py       # API endpoints
â”‚   â”‚   â””â”€â”€ hackrx_models.py
â”‚   â””â”€â”€ core/             # Extraction logic
â”‚       â”œâ”€â”€ ocr_processor.py
â”‚       â”œâ”€â”€ bill_extractor.py
â”‚       â”œâ”€â”€ page_classifier.py
â”‚       â””â”€â”€ ...
â”œâ”€â”€ config/               # Configuration
â”œâ”€â”€ tests/                # Tests
â”œâ”€â”€ run.py                # Server launcher
â””â”€â”€ requirements.txt      # Dependencies
```

## ğŸ¯ Features

- **Document URL Processing** - Direct image URL input
- **OCR Integration** - Google Cloud Vision with fallback
- **Page Classification** - Auto-categorizes pages (Bill Detail/Final Bill/Pharmacy)
- **Accurate Extraction** - Table parsing with column detection
- **No Missed Items** - Comprehensive extraction strategies
- **No Double-Counting** - Deduplication logic

## ğŸš¢ Deployment

### Vercel (Recommended - Serverless)

```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel --prod
```

Your API will be at: `https://your-project.vercel.app/api/extract`

### Render (Free)

1. Create account at [render.com](https://render.com)
2. Connect GitHub repository
3. Create Web Service
4. Set build command: `pip install -r requirements.txt`
5. Set start command: `uvicorn src.api.main:app --host 0.0.0.0 --port $PORT`
6. Add environment variables (optional):
   - `GOOGLE_APPLICATION_CREDENTIALS` (as secret file)
7. Deploy

### Railway

1. Create account at [railway.app](https://railway.app)
2. Deploy from GitHub
3. Railway auto-detects Python
4. Add environment variables
5. Deploy

## ğŸ”§ Troubleshooting

**Server won't start?**
- Check port 8000 is available
- Verify virtual environment is active

**Low accuracy?**
- Set up Google Cloud Vision API
- Ensure high-quality input images

**Import errors?**
- Reinstall: `pip install -r requirements.txt --force-reinstall`

## ğŸ“š Documentation

- **API Docs**: http://localhost:8000/docs (when server running)
- **GitHub**: [Repository Link](https://github.com/divyanshsaraswat/main_bfhl_submission)

---

**Version**: 2.0.0  
**License**: MIT
